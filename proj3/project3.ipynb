{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "259dcdd3",
   "metadata": {},
   "source": [
    "# Laboratory 3: Deep Learning and Modeling Materials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qWAmspvYNNrF",
   "metadata": {
    "id": "qWAmspvYNNrF"
   },
   "source": [
    "We start with the prerequisites for the lab. It's always good to put this in at the beginning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc5f50c",
   "metadata": {
    "id": "9fc5f50c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import spdiags,linalg,eye\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Sampler, BatchSampler, Dataset, DataLoader, Subset, SubsetRandomSampler, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wXFVR2cpOPCt",
   "metadata": {
    "id": "wXFVR2cpOPCt"
   },
   "outputs": [],
   "source": [
    "%pip install torchmetrics\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901a0423",
   "metadata": {
    "id": "901a0423"
   },
   "source": [
    "## Project Part 1 : Ising model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bba0684",
   "metadata": {
    "id": "1bba0684"
   },
   "source": [
    "No numerical physics class would be complete without doing the Ising model. Howevr, because we want to be starte of the art on this. We are going to do the Ising model in way that is a little bit different than what you have done in the past. We are going to do the Ising model with Deep learning. The first part of this project will largely follow work done in this nature paper\n",
    "\n",
    "https://arxiv.org/abs/1605.01735 \n",
    "\n",
    "This captures much of the core ideas that we want in building simulators, and, of course highlights the basic scheme that we get in an Ising model. \n",
    "\n",
    "Our first step is to setup the Ising model\n",
    "\n",
    "### Step 1.1: The lattice Ising Model \n",
    "\n",
    "\n",
    "The Ising model is a mathematical model used to describe the behavior of a collection of interacting magnetic moments, such as atoms in a solid or spins in a lattice. The model is named after Ernst Ising, a physicist who first proposed it in 1925.\n",
    "\n",
    "#### 1.1.1   Setting up Model\n",
    "\n",
    "In the Ising model, each magnetic moment is represented by a spin variable, which can take on the values of +1 or -1. The model assumes that these spins interact only with their nearest neighbors in a lattice, and that the interaction between them is influenced by an external magnetic field.\n",
    "\n",
    "The Hamiltonian of the Ising model describes the energy of the system, and is given by:\n",
    "\n",
    "$$\n",
    "H = -J \\sum_{i,j} s_{i} s_{j} - \\mu_{b} \\sum_{j} B_{j} s_{j}\n",
    "$$\n",
    "\n",
    "where J is the exchange interaction strength between neighboring spins, $\\mu$ is the magnetic moment of each spin, $B_{j}$ is the external magnetic field, and the first sum is taken over all pairs of nearest-neighbor spins in the lattice.\n",
    "\n",
    "The Ising model exhibits a phase transition, which is a sudden change in the behavior of the system as a parameter is varied. In the absence of an external magnetic field (B=0), the model exhibits a phase transition at a critical temperature known as the Curie temperature (Tc). Below the critical temperature, the system exhibits long-range order, with all spins aligning in the same direction, resulting in a net magnetization. Above the critical temperature, the system becomes disordered, with spins pointing in random directions, and the net magnetization vanishes.\n",
    "\n",
    "The critical behavior of the Ising model at the phase transition is described by universal scaling laws, which are independent of the microscopic details of the system. These scaling laws have been used to study a wide range of physical systems, including magnets, fluids, and even social networks.\n",
    "\n",
    "As a first step write (split the below code into multiple steps to build the concept and guide the the student)\n",
    "\n",
    "As an example of how we will setup the Ising model, see the initialize code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef24c1d",
   "metadata": {
    "id": "5ef24c1d"
   },
   "outputs": [],
   "source": [
    "np.random.seed(20)\n",
    "\n",
    "def initialize(N):   \n",
    "    state = 2*np.random.randint(2, size=(N,N))-1\n",
    "    return state\n",
    "\n",
    "N=4\n",
    "test=initialize(N)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f413bd5",
   "metadata": {
    "id": "2f413bd5"
   },
   "source": [
    "Ok, so now that we have done that let's define a Hamiltonian that will output the energy of the above grid. For this grid, we will use wrap-around (video-game) coordinates whereby the coordinate for $j+1 \\forall j \\geq N j+1\\rightarrow j \\mod N$ or in other words the in a 4x4 model the spin at x=0 y=2 can contribute to the x=3 y=2 neighbor spin the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc05e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION\n",
    "def hamiltonian(iArr,N):\n",
    "    return energy\n",
    "\n",
    "hamiltonian(test,N)\n",
    "#print energy should be 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1d0ef7",
   "metadata": {},
   "source": [
    "The above energy with the random seed should give us a value of 4. \n",
    "\n",
    "Now we would like to come up with a strategy to evolve the spin configurations of the Ising model. To do this we are going to follow a Markov Chain Monte-Carlo Proposal strategy.  For this write a Metropolis algorithm that \n",
    "\n",
    " * Flips the spin of the i,j-th element of the grid\n",
    " * Computes $\\Delta H=E_{\\rm after}-E_{\\rm before}$ the change in energy for that element\n",
    " * Updates the spin flip with probability $p < e^{-\\frac{\\Delta H}{k_{b} T} }$ \n",
    "\n",
    "Note that we often define temperature in the Ising model using a variable $\\beta=\\frac{1}{k_{b}T}$. The update need not be temperature.  Additionally, to make our units extra simple we will set the Boltzman Constant $k_{b}=1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7972cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(i,j,iArr,Beta):\n",
    "    return\n",
    "\n",
    "print(\"Before Flip:\\n\",test)\n",
    "flip(2,1,test,1)\n",
    "print(\"After Flip:\\n\",test)\n",
    "#the 2,1 element should go from -1 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3b08d7",
   "metadata": {},
   "source": [
    "Now define the magnetization of the system. This is just the sum over *all* the spins in the array: \n",
    "\n",
    "$$\n",
    "M=\\sum_{i\\in {\\rm Lattice}} \\sigma_{i}\n",
    "$$\n",
    "\n",
    "Write a function to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9f8bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag(iArr):\n",
    "    return \n",
    "print(\"magnetization:\",mag(test))#Should be zero if you flipped 2,1 correctly, otherwise from raw is -2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d799a01f",
   "metadata": {},
   "source": [
    "Write a function that tries to flip every element in the array in random order.  Use the functions above to help you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad5a2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_rand(iArr,N,TM1):\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4b6250",
   "metadata": {},
   "source": [
    "Finally, we can put it all together by adding a plotting function that can allow us to make a viedeo of the phase transition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebb68c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 843
    },
    "id": "5ebb68c1",
    "outputId": "21c3a317-2dbe-4c69-df80-f98a8554e802"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "def mapPlot(ax,fig, iArr, i, N, images):\n",
    "    plt.cla()\n",
    "    X, Y = np.meshgrid(range(N), range(N))\n",
    "    #plt.setp(sp.get_yticklabels(), visible=False)\n",
    "    #plt.setp(sp.get_xticklabels(), visible=False)      \n",
    "    ax.pcolormesh(X, Y, iArr, cmap=plt.cm.RdBu);\n",
    "    ax.text(0.6, 0.3,'Time=%d'%i,fontdict={'size': 24, 'color':  'red'})#; plt.axis('tight')    \n",
    "    fig.canvas.draw()       # draw the canvas, cache the renderer\n",
    "    image  = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image  = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    images.append(image)\n",
    "\n",
    "def runTemp(iT,iN,images,fig,ax,eqSteps=500,mcSteps=500):\n",
    "    pArr = initialize(iN)         # initialise\n",
    "    beta=1.0/iT \n",
    "    for i in range(eqSteps):         # equilibrate\n",
    "        update_rand(pArr, iN, beta)   \n",
    "    \n",
    "    for i in range(mcSteps):\n",
    "        update_rand(pArr, iN, beta)           \n",
    "        Ene = hamiltonian(pArr, iN)     # calculate the energy\n",
    "        Mag = mag(pArr)        # calculate the magnetisation\n",
    "        if i % 5 == 0: \n",
    "            mapPlot(ax,fig,pArr,i,iN,images)\n",
    "\n",
    "images=[]\n",
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "runTemp(1.00,32,images,fig,ax)\n",
    "imageio.mimsave('./test.gif', images, fps=10)\n",
    "Image(open('test.gif','rb').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb394b6f",
   "metadata": {},
   "source": [
    "Play around with the tempature. How does the Ising model look for different tempatures? \n",
    "\n",
    "Do you visualize a phase transition? (if you are impatient, move on!0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ac1053",
   "metadata": {},
   "source": [
    "#### Step 1.1.2 Modelling the Phase transition "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119a7d1b",
   "metadata": {},
   "source": [
    "Now, what we would like to do for each of our simulations is compute a bunch of quantities about the matter. In particular, we would like to compute the following quantities for the Ising model: \n",
    "\n",
    " * Average Energy $\\langle E \\rangle$ averaged over all the cells of the Ising model\n",
    " * Average Magnetization $\\langle M \\rangle$ averaged over all the cells of the Ising model\n",
    " * Specific Heat $C=\\frac{\\langle E^{2}\\rangle - \\langle E\\rangle^{2}}{T^{2}}$ where $E$ is the cell energy averaged over all the cells of the Ising model\n",
    " * Magnetic Susceptibility $\\chi=\\frac{\\langle M^{2}\\rangle - \\langle M\\rangle^{2}}{T}$ where $M$ is the magnetization averaged over all of the cells in the Ising model\n",
    "\n",
    "Now the importance of this is that we would like to scan the temperature and observe a phase transition. The specific heat,  in particular, has an infinite discontinuity in the precence of a phase trasition. \n",
    "\n",
    "In the below modify the function to output thse variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d580639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTemp(iT,iN,images,fig,ax,eqSteps=500,mcSteps=500):\n",
    "    pArr = initialize(iN)         # initialise\n",
    "    #initial variables? \n",
    "    beta=1.0/iT \n",
    "    for i in range(eqSteps):         # equilibrate\n",
    "        update_rand(pArr, iN, beta)   \n",
    "    \n",
    "    for i in range(mcSteps):\n",
    "        update_rand(pArr, iN, beta)           \n",
    "        Ene = hamiltonian(pArr, iN)     # calculate the energy\n",
    "        Mag = mag(pArr)        # calculate the magnetisation\n",
    "\n",
    "        #perhaps some code here to get below\n",
    "        \n",
    "    #compute the values for E,M,C,X here\n",
    "    E = \n",
    "    M = \n",
    "    C = \n",
    "    X = \n",
    "    return E,M,C,X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fff33",
   "metadata": {},
   "source": [
    "Now we have computed all of these things, lets go ahead and scan the temperature to see what is going on. Make a scan of temperature from $k_{b}T = 1.5$ to $3.3$. \n",
    "\n",
    "As you scan along plot the different values for E,M,C,$\\chi$ Where do you see the phase transition? What characterizes this phase transition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c06b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=#Something (your choice, choose wisely)\n",
    "nt =#Number of temperature points\n",
    "T  = #np.linspace(1.5-ish,3.3-ish,nt) #again pick\n",
    "E,M,C,X = np.zeros(nt), np.zeros(nt), np.zeros(nt), np.zeros(nt)\n",
    "for temp in tqdm (range (nt), desc=\"Loading...\"):\n",
    "    E[temp],M[temp],C[temp],X[temp] = runTemp(T[temp],N,images,fig,ax,eqSteps=500,mcSteps=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18994819",
   "metadata": {},
   "source": [
    "Now, given our above simulation. Go ahead and plot the the various parameters. What do you see? (It might be worth checking this with resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fecde19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "id": "5fecde19",
    "outputId": "539b04ac-a780-4a71-9af3-7901db86d669"
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(18, 10)); #  \n",
    "\n",
    "sp =  f.add_subplot(2, 2, 1 );\n",
    "plt.scatter(T, E, s=50, marker='o', color='IndianRed')\n",
    "plt.xlabel(\"Temperature (T)\", fontsize=20);\n",
    "plt.ylabel(\"Energy \", fontsize=20);         plt.axis('tight');\n",
    "\n",
    "\n",
    "sp =  f.add_subplot(2, 2, 2 );\n",
    "#Plot magnetization\n",
    "\n",
    "sp =  f.add_subplot(2, 2, 3 );\n",
    "#Plot specific heat\n",
    "\n",
    "sp =  f.add_subplot(2, 2, 4 );\n",
    "#Plot magnetic susceptibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e3ce50",
   "metadata": {
    "id": "41e3ce50"
   },
   "source": [
    "From the above, it should be clear there is a critical temperature for the Ising model. Its in weird units, but we could easily conver this to a normal temperature. The other thing you can see wright away is how this material magnetizes and how it can change as a function of the different temperature regimes.\n",
    "\n",
    "The full 2D Ising model has also been solved analytically, with a complete solution coming in the past 10 years. This was the motivation for the Fields medal in 2022 for Hugo Duminil-Copin at the University of Geneva. That being said the properties of criticallity and a simplfied solution have been known since 1950.\n",
    "\n",
    "Can you validate that you get the right critical tempature from analytic calcualtions ($T_{c} = 2/\\log(1+\\sqrt{2})$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4860916",
   "metadata": {},
   "source": [
    "## Step 1.2:  Constructing Ising Model Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f619e17",
   "metadata": {},
   "source": [
    "Now that we have generated an Ising model, we want to build an optimized scheme to run the Ising model many times so that we can train a neural network to understand the critical temperature of the ising model.\n",
    "\n",
    "#### 1.2.1 Training an NN\n",
    "\n",
    "For this part of the lab, we would like to generate Ising Monte Carlo Simulations where we randomly sample many configurations, and we the evolve the configuration at a specific temperature and then save it. Practically means we need to make simulated events where in each event, we\n",
    "\n",
    "Randomly sample a config\n",
    "Evolve that config  ð‘ steps ( ð‘â‰ˆ500 )\n",
    "Save the evolved configuration, magnetization and temperature\n",
    "Repeat the above nsim times and write this all to disk\n",
    "Once, we have done that then we can use the datasets have generated to make a neural network that takes as input the random configuration and outputs the temperature.\n",
    "\n",
    "So now lets make a class that generates Ising configurations. We can use use the previous functions. The important function in our class is the simulate_save, this will write a file with all of our Ising simulations.\n",
    "\n",
    "A class setup is below for you to fill out.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d8c6fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "id": "d9d8c6fc",
    "outputId": "3862808f-5e0a-4407-9410-dc0239064a58"
   },
   "outputs": [],
   "source": [
    "import h5py \n",
    "\n",
    "class Ising():\n",
    "    \n",
    "    def __init__(self, iN, Temp):\n",
    "        self.N   = iN\n",
    "        self.T   = Temp\n",
    "        self.arr = self.initialize()\n",
    "        self.steps = 300\n",
    "        #History over simulatinp\n",
    "        self.E   = np.array([])\n",
    "        self.M   = np.array([])\n",
    "        self.C   = np.array([])\n",
    "        self.X   = np.array([])\n",
    "        self.nsim = 1000\n",
    "        \n",
    "    def initialize(self):   \n",
    "        #use previous function\n",
    "        return state\n",
    "    \n",
    "    def simulate(self):\n",
    "        beta = 1./self.T\n",
    "        for i in range(self.steps):\n",
    "            update_rand(self.arr, self.N, beta)           \n",
    "            Ene = hamiltonian(self.arr, N)\n",
    "            Mag = mag(self.arr)\n",
    "            #Now save energy magnetization \n",
    "            self.E   = np.append(self.E,Ene)\n",
    "            self.M   = np.append(self.M,Mag)\n",
    "            #Now COMPUTE specific Heat and Magnetic suscpetilibity\n",
    "            #HINT, consider what the meaning of RMS of Energy and Magnetization are\n",
    "            #Perhaps consider a sliding window over the last hundred steps\n",
    "            pC  = #code here\n",
    "            pX  = #code here\n",
    "            self.C   = np.append(self.C,pC)\n",
    "            self.X   = np.append(self.X,pX)\n",
    "\n",
    "    def simulate_save(self,pre=''):\n",
    "        h5f  = h5py.File((pre)+'data_'+str(self.T)+'.h5', 'a')\n",
    "        data = np.array([])#np.empty((1,self.N,self.N), int)\n",
    "        mags = np.array([])\n",
    "        TM1  = 1./self.T\n",
    "        for n in range(self.nsim):\n",
    "            if n % 25 == 0:\n",
    "                print(\"sim\",n)\n",
    "            self.initialize()\n",
    "            ## Add code to run simulate the ising model nsteps\n",
    "            ## update self.arr  \n",
    "\n",
    "            #for each simulation we want to save the magnetization and the array      \n",
    "            pMag = mag(self.arr)\n",
    "            data = np.append(self.arr,data)\n",
    "            mags  = np.append(pMag,mags)\n",
    "        #now we write the output array into a dataset\n",
    "        data = np.reshape(data,(self.nsim,self.N,self.N))\n",
    "        h5f.create_dataset('data', data=data)\n",
    "        h5f.create_dataset('mag' , data=mags)\n",
    "        h5f.close()\n",
    "                    \n",
    "    def lastAvg(self):\n",
    "        avgE = np.mean(self.E[500:-1])\n",
    "        avgM = np.mean(self.M[500:-1])\n",
    "        avgC = np.std(self.E[500:-1])\n",
    "        avgX = np.std(self.M[500:-1])\n",
    "        return avgE,avgM,avgC,avgX\n",
    "        \n",
    "    def plotEvol(self):\n",
    "        ts = range(len(self.E))\n",
    "        f = plt.figure(figsize=(18, 10)); #  \n",
    "        sp =  f.add_subplot(2, 2, 1 );\n",
    "        plt.scatter(ts, self.E, s=50, marker='o', color='IndianRed')\n",
    "        plt.xlabel(\"step\", fontsize=20);\n",
    "        plt.ylabel(\"Energy \", fontsize=20);         plt.axis('tight');\n",
    "\n",
    "        #PLOT THE MAGNETIZATION, SPECIFIC HEAT AND SUSCEPTIBILITY\n",
    "        \n",
    "test = Ising(64,3.4)\n",
    "test.simulate()\n",
    "test.plotEvol()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534c156e",
   "metadata": {
    "id": "534c156e"
   },
   "source": [
    "Alright now that we have a class to run our Ising model and save things to disk we can go ahead and generate some samples following the code below, lets first generate a test sample so that we understand how to train the neural network. For this, lets just generate 10 test samples for each point, this shouldn't take too long, and will allow us to setup the neural network. \n",
    "\n",
    "Also, to make our ising model manageable, lets use a 32x32 Ising model. Note, feel free to change this! Second Note, this box will take a bit of time to run, its set up to do test run with 10 first, but at some point you should switch to 500.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17fd1d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e17fd1d0",
    "outputId": "a437e96d-d4b6-4d7b-ffaa-568a9d09e79c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "nt=20\n",
    "T       = np.round(np.linspace(1.53, 3.28, nt),2)\n",
    "print(T)\n",
    "for temp in tqdm (range (nt), desc=\"Loading...\"):\n",
    "    #Some hacky code to clean up things\n",
    "    filename='data_'+str(T[temp])+'.h5'\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except OSError:\n",
    "        pass\n",
    "    test = Ising(32,T[temp])\n",
    "    test.nsim=10#500 => \n",
    "    test.simulate_save()\n",
    "    \n",
    "f = h5py.File('data_1.53.h5', 'r') \n",
    "list(f.keys())\n",
    "f['data'].shape\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb03b058",
   "metadata": {
    "id": "cb03b058"
   },
   "source": [
    "Now we would like to develop a neural network that will take in this dataaset and train for whether the sample has undergood a phase transition. \n",
    "\n",
    "Before we build the Neural Network, we are going to use Torch Dataset to process and format the data. Setting this up is a little annoying so we will just write the code for this down here, and we will provide a little example of how to read a Torch DataLoaer. \n",
    "\n",
    "The one part that we will leave for you to figure out is what are the right labels and how do you split up the testing and training dataset to ensure your network learns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ff092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(Dataset):\n",
    "    def __init__(self, samples, labels, temps):\n",
    "        super(DataSet, self).__init__()\n",
    "        self.labels  = labels\n",
    "        self.samples = samples\n",
    "        self.temps   = temps\n",
    "        if len(samples) != len(labels):\n",
    "            raise ValueError(\n",
    "                f\"should have the same number of samples({len(samples)}) as there are labels({len(labels)})\")\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        y = self.labels[index]\n",
    "        x = self.samples[index]\n",
    "        t = self.temps[index]\n",
    "        return x, y, t\n",
    "\n",
    "\n",
    "#Here is some code to read all the different files and make a dataset\n",
    "all_data  = None\n",
    "all_temps = None\n",
    "for temp in tqdm (range (nt), desc=\"Loading...\"):\n",
    "    f = h5py.File('data_'+str(T[temp])+'.h5', 'r')\n",
    "    if temp == 0:\n",
    "        all_data  = f['data']\n",
    "        all_temps = np.ones(all_data.shape[0])*temp\n",
    "    else:\n",
    "        all_data  = np.append(all_data, f['data'],axis=0)\n",
    "        all_temps = np.append(all_temps,np.ones(f['data'].shape[0])*temp)\n",
    "    \n",
    "all_data    = np.reshape(all_data,(all_data.shape[0],all_data.shape[1]*all_data.shape[2]))\n",
    "all_labels  = #build a numpy array that has labels 1 for below phase transition and 0 for above transition\n",
    "all_dataset = DataSet(samples=all_data.astype(\"float32\"),labels=all_labels,temps=all_temps)\n",
    "\n",
    "#Finally, we will split the dataset randomly\n",
    "data_train, data_test = #code to randomly split test and training\n",
    "#And a loader\n",
    "batch=10\n",
    "train_loader = DataLoader(data_train, batch_size=batch,shuffle=True)\n",
    "#here is an example how it works\n",
    "for count, (x, y, t) in enumerate(train_loader):\n",
    "    print(count,\"x value:\",x,x.shape,\"\\n Label:\",y,y.shape,\"\\n Temp:\",t,t.shape)\n",
    "    if count > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09fef75",
   "metadata": {
    "id": "b09fef75"
   },
   "source": [
    "Now finally, setup a neural network that reads in the inputs, and then trains to find the label. Create your own neural network that takes the input as a vector or image (note you can use a Dense network or a CNN). \n",
    "\n",
    "Additionally, add a loss that classifies whether the data is above or below the critical tempeature. Run the training so that we get good performance for the classification of above or below the critical temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfdb1cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "adfdb1cd",
    "outputId": "7147d6bf-b4b0-4fb2-bc3b-8a581a8a3395"
   },
   "outputs": [],
   "source": [
    "class simple_MLP_4layer(torch.nn.Module):\n",
    "    def __init__(self,input_size,out_channels=1,nhidden=64):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            #Design your own neural network\n",
    "        )\n",
    "        self.output  = ##Perhaps an activation between 0 and 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "                \n",
    "def train(model,n_epochs=20):\n",
    "    opt       = torch.optim.Adam(model.parameters(),lr=0.005)\n",
    "    criterion = #### come up with a loss function that is appropriate\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train(True)\n",
    "        running_loss = 0.0; updates=0\n",
    "        for x, y, t in train_loader:\n",
    "            opt.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            loss  = criterion(y_hat.flatten(),y) \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            running_loss += loss\n",
    "            updates +=1\n",
    "            del x,y\n",
    "        print('Epoch: {} LOSS train: {} '.format(epoch,running_loss/(updates*batch)))\n",
    "\n",
    "model     = simple_MLP_4layer(all_data.shape[1],out_channels=1,act_out=True) \n",
    "train(model,n_epochs=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848ad5c5",
   "metadata": {
    "id": "848ad5c5"
   },
   "source": [
    "Now run the validation and confirm that temperature prediction of the neural network. Plot the true value of the vadliation set agains the prediction. How clos is the preidction? What is the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a21b382",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a21b382",
    "outputId": "63922958-83b2-4ed7-e359-55369563a530"
   },
   "outputs": [],
   "source": [
    "model.train(False)\n",
    "test_accuracy = Accuracy(task=\"binary\", num_classes=2)\n",
    "for x, y, t in test_loader:\n",
    "    with torch.no_grad():\n",
    "            #Run inference on test dataset    \n",
    "            #Insert code here\n",
    "\n",
    "#compute accuracy\n",
    "#plot Prediction vs tempature for truth and pred\n",
    "#Do you get good validation? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75db435",
   "metadata": {},
   "source": [
    "#### 1.2.2 NN application on Triangle Ising Model"
   ]
  },
  {
   "attachments": {
    "triangular_lattice.webp": {
     "image/webp": "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"
    }
   },
   "cell_type": "markdown",
   "id": "3e8e84e6",
   "metadata": {},
   "source": [
    "Ok, so once our validation is looking good, we want to show are neural network has actually learned something non-trivial for that we want to make a different Magnetic fild configuration with a different, but similar Hamiltonian, and see if we can us our neural network to predict the temuprature change. \n",
    "\n",
    "As a consequence, write a function for the Hamiltonian of the Triangular Ising model. We can define the triangular Ising model as a trigualr array as oppose to a square array like in the picture below fore [here](https://link.springer.com/article/10.1134/S1063776122050016)\n",
    "![triangular_lattice.webp](attachment:triangular_lattice.webp)\n",
    "\n",
    "The Hamiltonian is again the Ising Hamiltonian except now we sum over all 6 elements $i,j$ connected to a point. \n",
    "$$\n",
    "H = -\\frac{1}{2}\\sum_{i,j\\in{adjacent to i}} \\sigma_{i}\\sigma_{j} - h \\sum_{i} \\sigma_{i}\n",
    "$$\n",
    "\n",
    "Just fousing on teh first term, write a Hamiltonian that will act on an N$\\times$N array following a pattern above  to create the triangular array. We can again use a video game Geometry to make this easier. Connect one end to the other. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc55fb75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fc55fb75",
    "outputId": "e741a856-d9e4-49e3-9d94-75c0a841e6e6"
   },
   "outputs": [],
   "source": [
    "#Now lets define the trignular ising \n",
    "def hamiltonian(iArr,N):\n",
    "    #Compute the hamiltonian (note if you use this function you don't need to redeclare the above class)\n",
    "    energy = 0\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "     \n",
    "    return energy\n",
    "\n",
    "def flip(i,j,iArr,beta):\n",
    "    #finally run the Markov Chain process that computes delta energy, and based on the Markov deicison flips the spins. \n",
    "\n",
    "#Run some checks? \n",
    "#test.simulate()\n",
    "#E[temp],M[temp],C[temp],X[temp]=test.lastAvg()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f949706b",
   "metadata": {
    "id": "f949706b"
   },
   "source": [
    "Finally, run the neural entwork on a dataset for triangular Ising models. Show that you can predict the correct tempearture, what is it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997a7583",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "id": "997a7583",
    "outputId": "a4d91e00-b2d8-4687-b2d7-ab7a99d3a038"
   },
   "outputs": [],
   "source": [
    "T       = np.round(np.linspace(1.53, 6.86, 28),2);\n",
    "for temp in tqdm (range (9), desc=\"Loading...\"):\n",
    "    filename='tridata_'+str(T[temp])+'.h5'\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except OSError:\n",
    "        pass\n",
    "    test = Ising(32,T[temp])\n",
    "    test.nsim=500\n",
    "    test.simulate_save('tri')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b152aec1",
   "metadata": {
    "id": "b152aec1"
   },
   "source": [
    "Finally, run the neural network on a dataset for triangular Ising models. Show that you can predict the correct tempearture, what is it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3867c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets test it on something different\n",
    "def load():\n",
    "    #following above, read teh data and output a dataset\n",
    "    return data_tri_train, data_tri_test\n",
    "\n",
    "data_tri_train, data_tri_test = load()\n",
    "batch=1000\n",
    "test_tri_loader = DataLoader(data_tri_test, batch_size=batch,shuffle=True)\n",
    "\n",
    "#again following above, plot the temp applying your prevoiusly trained NN to the triagle boltzman\n",
    "model.train(False)\n",
    "for x, y, t in test_tri_loader:\n",
    "    with torch.no_grad():\n",
    "\n",
    "#What is accuracy?     \n",
    "#plot Score vs Temp where is the phase transition, is it consistent with truth see arxiv paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f34e4b",
   "metadata": {},
   "source": [
    "Ok, so we should now have a result, and you can see hwo this behaves. From this we can ask a few questions:  \n",
    " * Do you see a phase transition?  \n",
    " * Does this agree with the paper? \n",
    " * What can you do to make this more accurate?\n",
    " \n",
    "Now there are many follow ups to this study. However, I would like to highlight that he big gains that come from thsi are not the network itself, its more that the NN has been able to do a visual inspection of a material and made conclusions that are not necessarily obvious. Using this can lead to better analysis of data. Moreover, we can ask ourselves the question if we can accurately predict properties of materials can we use this to advance our understanding. \n",
    "\n",
    "In the following section, we will explore how we can use Machine learned distributions to rapdily accelerate simulation allow us to perform advanced lattice measurements leading to critical material properties. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68648ab5",
   "metadata": {
    "id": "68648ab5"
   },
   "source": [
    "# Part 2: Scalar field theory on a lattice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Sz6rnF3EIS_z",
   "metadata": {
    "id": "Sz6rnF3EIS_z"
   },
   "source": [
    "In this part of the tutorial, we will explore the methods of lattice Quantum Chromodynamics. Quantum Chromodynamics is the theory that describes the strong interaction between quarks and gluons, which are fundamental particles that make up mesons and hadrons. These particles constitute the majority of visible matter in the Universe. QCD is a crucial component of the Standard Model (SM) and is used to investigate physical phenomena such as the anomalous magnetic moment of the muon and the interactions of Dark Matter with Nuclei.\n",
    "\n",
    "Due to its large coupling constant, QCD cannot be studied using perturbation theory. Well-established non-perturbative method, lattice QCD enables computations of physical observables though numerical simulations. Some of the most famous results obtained with lattice QCD are the study of quark potential, hadron spectrum, and hadron structure.\n",
    "\n",
    "In this part of the tutorial, we will focus on the toy lattice QCD model - the lattice scalar field theory. Despite being the simplest interacting theory, it is also one of the most effective theoretical tools for studying critical phenomena in a wide variety of physical systems. Additionally, the Higgs field in the SM is a scalar field that breaks the weak isospin symmetry of the electroweak interaction and generates mass to many particles.\n",
    "\n",
    "Instead of using the traditional lattice QCD approach, we will explore recent developments in machine learning. This method has already been applied to some toy models and has demonstrated its effectiveness by significantly reducing the uncertainties of physical observables by several orders of magnitude while guaranteeing correctness [arXiv:2003.06413, arXiv:2202.11712]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czqHV-9fsmFt",
   "metadata": {
    "id": "czqHV-9fsmFt"
   },
   "source": [
    "### Similarities between Scalar field theory and Ising Model\n",
    "\n",
    "The Ising model and scalar field theory are seemingly different models at the microscopic level, but they share some fundamental properties that make them belong to the same universality class.\n",
    "\n",
    "One of the key similarities is the global symmetry $Z_2$, which is the symmetry of the Ising model with respect to the flipping of all spins. In scalar field theory, this symmetry corresponds to the invariance of the Lagrangian under the transformation $\\phi \\rightarrow -\\phi$, where $\\phi$ is the scalar field.\n",
    "\n",
    "Another important property shared by the two models is that they both undergo a phase transition at a critical temperature or coupling strength, respectively. At this critical point, the correlation length diverges, and the system exhibits scaling behavior that is independent of the microscopic details of the system.\n",
    "\n",
    "This scaling behavior is described by critical exponents, which characterize the power-law behavior of various physical observables near the critical point. These critical exponents are universal, meaning that they are the same for all models in the same universality class, regardless of the specific microscopic details.\n",
    "\n",
    "In summary, while the Ising model and scalar field theory may be very different at the microscopic level, they share some fundamental properties that make them belong to the same universality class. This universality allows us to study and understand the critical behavior of these models without needing to know their microscopic details, but only their macroscopic properties.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "by52H_GXIQUw",
   "metadata": {
    "id": "by52H_GXIQUw"
   },
   "source": [
    "## Intro to LQCD\n",
    "\n",
    "In lattice QCD the concept of continuous space-time is replaced with a 4D Euclidean lattice that has a constant lattice spacing denoted as $a$. The degrees of freedom in lattice QCD are classical field variables (rather than operators) that reside on the lattice. The Euclidean action $S_E$ of the system is discretized on the lattice such that in the limit $a â†’ 0$ the Euclidean continuum action is obtained. The Boltzmann weight factor $e ^{S_E}$ is used in subsequent computations. In order to study Euclidean correlators, the operators that appear in them are replaced by functionals that use the classical lattice field variables. The computation of Euclidean correlation functions in lattice QCD involves evaluating these functionals on a given lattice field configuration, weighting them with the Boltzmann factor, and integrating over all possible field configurations. We will mimic the whole approach in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZdNusq1qGFu5",
   "metadata": {
    "id": "ZdNusq1qGFu5"
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14997313",
   "metadata": {
    "id": "14997313"
   },
   "source": [
    "Let's begin by defining some useful helper functions before diving into the interesting stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ee373a",
   "metadata": {
    "id": "c6ee373a"
   },
   "outputs": [],
   "source": [
    "def torch_mod(x):\n",
    "    return torch.remainder(x, 2*np.pi)\n",
    "def torch_wrap(x):\n",
    "    return torch_mod(x+np.pi) - np.pi\n",
    "def grab(var):\n",
    "    return var.detach().cpu().numpy()\n",
    "\n",
    "def print_metrics(history, avg_last_N_epochs):\n",
    "  print(f'== Era {era} | Epoch {epoch} metrics ==')\n",
    "  for key, val in history.items():\n",
    "      avgd = np.mean(val[-avg_last_N_epochs:])\n",
    "      print(f'\\t{key} {avgd:g}')\n",
    "def moving_average(x, window=10):\n",
    "    if len(x) < window:\n",
    "       return np.mean(x, keepdims=True)\n",
    "    else:\n",
    "       return np.convolve(x, np.ones(window), 'valid') / window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GC67kDSeGqFd",
   "metadata": {
    "id": "GC67kDSeGqFd"
   },
   "source": [
    "We have also defined some functions for creating visually appealing plots. You may skip this part if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ivJj94EmGavs",
   "metadata": {
    "id": "ivJj94EmGavs"
   },
   "outputs": [],
   "source": [
    "def init_live_plot(dpi=125, figsize=(8,4)):\n",
    "    fig, ax_ess = plt.subplots(1,1, dpi=dpi, figsize=figsize)\n",
    "    plt.xlim(0, N_era*N_epoch)\n",
    "    plt.ylim(0, 1)\n",
    "    ess_line = plt.plot([0],[0], alpha=0.5) # dummy\n",
    "    plt.grid(False)\n",
    "    plt.ylabel('ESS')\n",
    "    ax_loss = ax_ess.twinx()\n",
    "    loss_line = plt.plot([0],[0], alpha=0.5, c='orange') # dummy\n",
    "    plt.grid(False)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    display_id = display(fig, display_id=True)\n",
    "    return dict(\n",
    "        fig=fig, ax_ess=ax_ess, ax_loss=ax_loss,\n",
    "        ess_line=ess_line, loss_line=loss_line,\n",
    "        display_id=display_id\n",
    "    )\n",
    "def update_plots(history, fig, ax_ess, ax_loss, ess_line, loss_line, display_id):\n",
    "    Y = np.array(history['ess'])\n",
    "    Y = moving_average(Y, window=15)\n",
    "    ess_line[0].set_ydata(Y)\n",
    "    ess_line[0].set_xdata(np.arange(len(Y)))\n",
    "    Y = history['loss']\n",
    "    Y = moving_average(Y, window=15)\n",
    "    loss_line[0].set_ydata(np.array(Y))\n",
    "    loss_line[0].set_xdata(np.arange(len(Y)))\n",
    "    ax_loss.relim()\n",
    "    ax_loss.autoscale_view()\n",
    "    fig.canvas.draw()\n",
    "    display_id.update(fig) # need to force colab to update plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "W0HN204SGzzn",
   "metadata": {
    "id": "W0HN204SGzzn"
   },
   "source": [
    "PyTorch is a flexible machine learning framework that enables the construction of complex neural networks. However, for this particular project, we will only be using two-dimensional convolutional neural networks with varying configurations. The code below defines a fabric function that constructs a CNN with user-specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0446c70",
   "metadata": {
    "id": "e0446c70"
   },
   "outputs": [],
   "source": [
    "def make_conv_net(*, hidden_sizes, kernel_size, in_channels, out_channels):\n",
    "    sizes = [in_channels] + hidden_sizes + [out_channels]\n",
    "    #assert packaging.version.parse(torch.__version__) >= packaging.version.parse('1.5.0')\n",
    "    assert kernel_size % 2 == 1, 'kernel size must be odd for PyTorch >= 1.5.0'\n",
    "    padding_size = (kernel_size // 2)\n",
    "    net = []\n",
    "    for i in range(len(sizes) - 1):\n",
    "        net.append(torch.nn.Conv2d(\n",
    "            sizes[i], sizes[i+1], kernel_size, padding=padding_size,\n",
    "            stride=1, padding_mode='circular'))\n",
    "        if i != len(sizes) - 2:\n",
    "            net.append(torch.nn.LeakyReLU())\n",
    "        else:\n",
    "            net.append(torch.nn.Tanh())\n",
    "    return torch.nn.Sequential(*net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7lqwaaMuHgpW",
   "metadata": {
    "id": "7lqwaaMuHgpW"
   },
   "source": [
    "As an example, we can use the following code to build a CNN with 2 hidden channels of size 8, a kernel size of 3, and 2 input channels and 4 output channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6W-PxiRnHtFI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6W-PxiRnHtFI",
    "outputId": "7dfa3ff3-3343-4b6b-f615-0d59965f681d"
   },
   "outputs": [],
   "source": [
    "m = make_conv_net(\n",
    "    hidden_sizes=[8,8],\n",
    "    kernel_size=3,\n",
    "    in_channels=2,\n",
    "    out_channels=4\n",
    ")\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bb86ee",
   "metadata": {
    "id": "b3bb86ee"
   },
   "source": [
    "## Scalar field theory on the lattice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vbKiXslKVMNT",
   "metadata": {
    "id": "vbKiXslKVMNT"
   },
   "source": [
    "$\\newcommand{\\n}[0]{\\vec{n}}$\n",
    "A simple discretization of the derivatives in the continuum Euclidean action gives rise to a valid lattice Euclidean action,\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "S^E_{\\text{cont}}[\\phi] &= \\int d^2\\vec{x} ~ (\\partial_\\mu \\phi(\\vec{x}))^2 + m^2 \\phi(\\vec{x})^2 + \\lambda \\phi(\\vec{x})^4 \\\\\n",
    "\\rightarrow S^E_{\\text{latt}}(\\phi) &= \\sum_{\\n} \\phi(\\n) \\sum_{\\mu \\in \\{1,2\\}}  \\left[ 2\\phi(\\n) - \\phi(\\n+\\hat{\\mu}) - \\phi(\\n-\\hat{\\mu}) \\right] + m^2 \\phi(\\n)^2 + \\lambda \\phi(\\n)^4 \\qquad (1)\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "where now $\\phi(\\n)$ is only defined on the sites of the $L_x \\times L_y$ lattice, $\\vec{n} = (n_x, n_y)$, with integer $n_x, n_y$, and $\\hat{\\mu}$ is an operator such that $\\hat{0} = (1, 0),\\hat{1} = (0, 1)$. We have implicitly moved to \"lattice units\" where $a=1$ such that $L_x, L_y, V$ are integers and all quantities are unitless. The discretized field $\\phi$ can therefore be thought of as an $(L_x \\times L_y)$-dimensional vector. We use periodic boundary conditions in all directions, i.e. $\\phi(L_x, y) \\equiv \\phi(0, y)$, etc. For convenience, we typically abbreviate $S^E_{\\text{latt}} \\equiv S$.\n",
    "\n",
    "More details on $\\phi^4$ lattice scalar field theory can be found in [this PhD thesis](https://edoc.hu-berlin.de/bitstream/handle/18452/14790/schroeder.pdf?sequence=1) from Ingmar Vierhaus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fZjspsSj68Eh",
   "metadata": {
    "id": "fZjspsSj68Eh"
   },
   "source": [
    "### Ising limit\n",
    "\n",
    "The action for scalar field theory defined above can be rewritten in a following form\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "S^E_{\\text{latt}}(\\phi) &= \\sum_{\\n} -2 \\kappa \\sum_{\\mu \\in \\{1,2\\}} \\phi(\\n) \\phi(\\n+\\hat{\\mu}) + \\phi(\\n)^2 + \\lambda' (\\phi(\\n)^2 - 1)^2 + constant \\qquad (2)\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "The Ising limit of scalar field theory is obtained by taking the limit $\\lambda \\rightarrow \\infty$. In this limit, the scalar field is constrained to take values only in the set ${\\pm 1}$, since any other value would result in an infinite potential energy contribution to the action.\n",
    "\n",
    "To see why this is the case, consider the potential energy term in the action:\n",
    "\n",
    "\\begin{equation}\n",
    "V(\\phi) = \\lambda'(\\phi^2 - 1)^2\n",
    "\\end{equation}\n",
    "\n",
    "For large $\\lambda$, this potential energy term dominates over the kinetic energy term, and the field $\\phi$ will tend to minimize the potential energy by taking values as close to $\\pm 1$ as possible.\n",
    "\n",
    "Substituting $\\phi(\\n) = \\pm 1$ into the action for scalar field theory, we get:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "S^E_{\\text{latt}}(\\phi) &= \\sum_{\\n} -2 \\kappa \\sum_{\\mu \\in {1,2}} \\phi(\\n) \\phi(\\n+\\hat{\\mu}) + constant\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "This is precisely the action for the two-dimensional Ising model on a lattice with coupling constant $J = 2\\kappa$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p6ROldsj_Ai-",
   "metadata": {
    "id": "p6ROldsj_Ai-"
   },
   "source": [
    "### **Exercise: rescaling bare parameters**\n",
    "\n",
    "Although we will be using form $(1)$ of the action in our work, form $(2)$ is more commonly used in literature. In this exercise, you will need to find the relationships between the parameters $(m,\\lambda)$ in eq. $(1)$ and the parameters $(\\kappa,\\lambda)$ in eq. $(2)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GHhj0aAX_leA",
   "metadata": {
    "id": "GHhj0aAX_leA"
   },
   "source": [
    "Answer:\n",
    "$$\n",
    "m^2 = \\frac{1-2\\lambda'}{\\kappa} - 4, \\, \\lambda = \\frac{\\lambda'}{\\kappa ^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff8a21",
   "metadata": {
    "id": "bcff8a21"
   },
   "source": [
    "The class below implements action $(1)$. Each instance of the class is a function $S$ with fixed $m^2$, $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12596766",
   "metadata": {
    "id": "12596766"
   },
   "outputs": [],
   "source": [
    "class ScalarPhi4Action:\n",
    "    def __init__(self, M2, lam):\n",
    "        self.M2 = M2\n",
    "        self.lam = lam\n",
    "    def __call__(self, phi):\n",
    "        action_density = torch.zeros_like(phi)\n",
    "        \n",
    "        # potential term\n",
    "        action_density += self.M2*phi**2\n",
    "        action_density += self.lam*phi**4\n",
    "        \n",
    "        # kinetic term (discrete Laplacian)\n",
    "        Nd = len(phi.shape)-1\n",
    "        dims = range(1,Nd+1)\n",
    "        for mu in dims:\n",
    "            action_density += 2*phi**2\n",
    "            action_density -= phi*torch.roll(phi, -1, mu)\n",
    "            action_density -= phi*torch.roll(phi, 1, mu)\n",
    "        return torch.sum(action_density, dim=tuple(dims))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691441e4",
   "metadata": {
    "id": "691441e4"
   },
   "source": [
    "Let us return to the idea of the phase transitions in these models. Just as the Ising Model exhibits an ordered phase below the critical temperature and a disordered one above, the scalar field theory has a symmetric phase and a broken symmetry phase.\n",
    "For simplicity, we restrict focus to the **symmetric phase**. The cell below instantiates an action for a set of parameters in this phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fecd4b2",
   "metadata": {
    "id": "1fecd4b2"
   },
   "outputs": [],
   "source": [
    "M2 = -4.0\n",
    "lam = 8.0\n",
    "\n",
    "phi4_action = ScalarPhi4Action(M2=M2, lam=lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29cea5a",
   "metadata": {
    "id": "c29cea5a"
   },
   "source": [
    "## Normalizing flows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d895eda",
   "metadata": {
    "id": "3d895eda"
   },
   "source": [
    "The lattice action defines the _target distribution_ $p$ over configurations $\\phi$,\n",
    "\\begin{equation}\n",
    "p(\\phi) = \\frac{1}{Z} e^{-S(\\phi)}, \\quad\n",
    "Z \\equiv \\int \\prod_{\\vec{n}} d\\phi(\\vec{n}) ~ e^{-S(\\phi)},\n",
    "\\end{equation}\n",
    "where $\\prod_{\\vec{n}}$ runs over all lattice sites $\\vec{n}$.\n",
    "Typically one uses algorithms like Hybrid Monte Carlo (HMC) to generate configurations from this distribution.\n",
    "\n",
    "Instead, a powerful method to generate samples from complicated distributions is to: \n",
    "1. draw samples $z$ from a simple distribution $r(z)$ (the _prior distribution_), then\n",
    "2. apply a deterministic change-of-variables $f$ (a _normalizing flow_ (NF)) to get transformed samples $\\phi = f(z)$.\n",
    "\n",
    "The prior $r$ and flow $f$ together define a _normalizing flow model_. Note that in this example, $z$ and $\\phi$ are both scalar fields.\n",
    "\n",
    "The transformed samples $\\phi$ are distributed according to the _model distribution_, $q$, whose density is given by the change-of-variables (or \"conservation of probability\") formula,\n",
    "\n",
    "\\begin{equation}\n",
    "    q(\\phi) = r(z) [J(z)]^{-1} = r(z) \\left|\\det_{kl} \\frac{\\partial f_k(z)}{ \\partial z_l} \\right|^{-1} .\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "$f$ must be **invertible** and **differentiable** for $q(\\phi)$ to be well-defined. For the model to be useful, $f$ must be expressive and the Jacobian determinant factor $J(z)$ must be efficient to calculate. As you'll see below, in some cases it is easy to compute $J$ even when the whole Jacobian matrix is intractable. \n",
    "\n",
    "<!-- Below we construct _coupling layers_ where only the diagonal elements are needed, because the Jacobian matrix is known to be triangular. -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52pdk-dUpLRg",
   "metadata": {
    "id": "52pdk-dUpLRg"
   },
   "source": [
    "\n",
    "### **A simple example**\n",
    "The Box-Muller transform is an example of this trick in practice: to produce Gaussian random variables, draw two variables $U_1$ and $U_2$ from $\\text{unif}(0,1)$ then change variables to\n",
    "\n",
    "\\begin{equation}\n",
    "    Z_1 = \\sqrt{-2 \\ln{U_1}} \\cos(2\\pi U_2)\n",
    "    \\quad \\text{and} \\quad\n",
    "    Z_2 = \\sqrt{-2 \\ln{U_1}} \\sin(2\\pi U_2).\n",
    "\\end{equation}\n",
    "\n",
    "The resulting variables $Z_1, Z_2$ are then distributed according to an uncorrelated, unit-variance Gaussian distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kEIpRg-lafkk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "kEIpRg-lafkk",
    "outputId": "64c63f13-c458-4820-947e-e12498862f27"
   },
   "outputs": [],
   "source": [
    "batch_size = 2**14\n",
    "u = np.random.random(size=(batch_size, 2))\n",
    "z = np.sqrt(-2*np.log(u[:,0]))[:,np.newaxis] * np.stack(\n",
    "    (np.cos(2*np.pi*u[:,1]), np.sin(2*np.pi*u[:,1])), axis=-1)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, dpi=125, figsize=(4,2))\n",
    "for a in ax:\n",
    "    a.set_xticks([-2, 0, 2])\n",
    "    a.set_yticks([-2, 0, 2])\n",
    "    a.set_aspect('equal')\n",
    "ax[0].hist2d(u[:,0], u[:,1], bins=30, range=[[-3.0,3.0], [-3.0,3.0]])\n",
    "ax[0].set_xlabel(r\"$U_1$\")\n",
    "ax[0].set_ylabel(r\"$U_2$\", rotation=0, y=.46)\n",
    "ax[1].hist2d(z[:,0], z[:,1], bins=30, range=[[-3.0,3.0], [-3.0,3.0]])\n",
    "ax[1].set_yticklabels([])\n",
    "ax[1].set_xlabel(r\"$Z_1$\")\n",
    "ax[1].set_ylabel(r\"$Z_2$\", rotation=0, y=.53)\n",
    "ax[1].yaxis.set_label_position(\"right\")\n",
    "ax[1].yaxis.tick_right()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J6r4VTayaebl",
   "metadata": {
    "id": "J6r4VTayaebl"
   },
   "source": [
    "\n",
    "We can analytically compute the density associated with output samples by the **change-of-variables formula** relating the _prior density_ $r(U_1, U_2) = 1$ to the _output density_ $q(Z_1, Z_2)$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    q(Z_1, Z_2) &= r(U_1, U_2) \\left| \\det_{kl} \\frac{\\partial Z_k(U_1, U_2)}{\\partial U_l} \\right|^{-1} \\\\\n",
    "    &= 1 \\times \\left| \\det \\left( \\begin{matrix}\n",
    "        \\frac{-1}{U_1 \\sqrt{-2 \\ln{U_1}}} \\cos(2\\pi U_2) &\n",
    "        - 2\\pi \\sqrt{-2 \\ln{U_1}} \\sin(2\\pi U_2) \\\\\n",
    "        \\frac{-1}{U_1 \\sqrt{-2 \\ln{U_1}}} \\sin(2\\pi U_2) &\n",
    "        2\\pi \\sqrt{-2 \\ln{U_1}} \\cos(2\\pi U_2)\n",
    "        \\end{matrix} \\right) \\right|^{-1} \\\\\n",
    "    &= \\left| \\frac{2 \\pi}{U_1} \\right|^{-1}.\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Here, the term $J(U_1, U_2) \\equiv \\left| \\det_{kl} \\frac{\\partial Z_k(U_1, U_2)}{\\partial U_l} \\right|$ is the determinant of the Jacobian of the transformation from $(U_1,U_2)$ to $(Z_1,Z_2)$. Intuitively, the Jacobian factor can be thought of as a change in volume element, therefore the change-of-variables formula must contain the inverse of this factor (spreading out volume decreases density). To complete the example, we can rearrange the change of variables to find $U_1 = \\exp(-(Z_1^2 + Z_2^2) / 2)$ and therefore\n",
    "\\begin{equation}\n",
    "    q(Z_1, Z_2) = \\frac{1}{2\\pi} e^{-(Z_1^2 + Z_2^2)/2}.\n",
    "\\end{equation}\n",
    "\n",
    "**NOTE**: In this example, the model has no free parameters because we didn't need any to create a transform that exactly reproduced our target distribution (independent, unit-variance Gaussian). In general, we may not know a normalizing flow that exactly produces our desired distribution, and so instead construct parametrized models that we can variationally optimize to _approximate_ that target distribution, and because we can compute the density these can be corrected to nevertheless guarantee exactness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9be32c",
   "metadata": {
    "id": "7b9be32c"
   },
   "source": [
    "### **Prior distribution**\n",
    "\n",
    "We choose the prior distribution to be independent and identically distributed Gaussians at each lattice site, with unit width and mean zero. This is easy to sample from, and intuitively gives a \"blank slate\" for $f$ to build correlations into.\n",
    "\n",
    "The cell below defines a class for this prior (which is really just a wrapper for PyTorch's normal distribution sampler), and shows how to instantiate it for lattice volume $L^2$.\n",
    "\n",
    "You will notice that in addition to just setting up a normal and sampling, we explicitly comput the log-likelihood (aka log probability). This strategy helps with the expressiveness and tells torch that this is differentiable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f48f60",
   "metadata": {
    "id": "b3f48f60"
   },
   "outputs": [],
   "source": [
    "class SimpleNormal:\n",
    "    def __init__(self, loc, var):\n",
    "        self.dist = torch.distributions.normal.Normal(\n",
    "            torch.flatten(loc), torch.flatten(var))\n",
    "        self.shape = loc.shape\n",
    "    def log_prob(self, x):\n",
    "        logp = self.dist.log_prob(x.reshape(x.shape[0], -1))\n",
    "        return torch.sum(logp, dim=1)\n",
    "    def sample_n(self, batch_size):\n",
    "        x = self.dist.sample((batch_size,))\n",
    "        return x.reshape(batch_size, *self.shape)\n",
    "    \n",
    "Lt, Lx = 8, 16\n",
    "lattice_shape = (Lt,Lx)\n",
    "prior = SimpleNormal(torch.zeros(lattice_shape), torch.ones(lattice_shape))\n",
    "print(\"Example:\",prior.sample_n(1).shape)\n",
    "print(\"Example values: \\n\",prior.sample_n(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788c0589",
   "metadata": {
    "id": "788c0589"
   },
   "source": [
    "### Coupling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d185e",
   "metadata": {
    "id": "8c2d185e"
   },
   "source": [
    "Expressive functions can be built through composition of simpler ones, i.e.\n",
    "\\begin{equation}\n",
    "    f = g_n \\circ g_{n-1} \\circ \\ldots \\circ g_1 \\Leftrightarrow f(z) = g_n(g_{n-1}(\\ldots g_1(z)))\n",
    "\\end{equation}\n",
    "When each simpler function is invertible and differentiable, the composed function is as well. \n",
    "\n",
    "**Coupling layers** are one approach to defining the $g_i$ in the composed function. For input variables $\\phi$, these functions are defined to update only the \"active\" subset $\\phi_1$ conditioned on the complimentary \"frozen\" subset $\\phi_2$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ff6d93",
   "metadata": {
    "id": "60ff6d93"
   },
   "source": [
    "A coupling layer $g(\\phi_1, \\phi_2) = (\\phi_1', \\phi_2')$ based on an *affine transformation* (ak transform that is just a shift, scale or stratech  see [here](https://en.wikipedia.org/wiki/Affine_transformation)), looks like\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  \\phi_1 '  &= e^{s(\\phi_2)} \\phi_1 + t(\\phi_2) \\\\\n",
    "  \\phi_2 '  &= \\phi_2\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "with inverse \n",
    "\n",
    "\\begin{equation}\\begin{aligned}\n",
    "  \\phi_1 &= e^{-s(\\phi_2')} \\left( \\phi_1' - t(\\phi_2') \\right)\n",
    "  \\\\\n",
    "  \\phi_2 &= \\phi_2'\n",
    "\\end{aligned}\\end{equation}\n",
    "\n",
    "**Note:** this equation is thinking of $\\phi_1$, $s$, $t$ as vectors over the active variables/sites, and $\\phi_2$ as a vector over the frozen variables/sites. The multiplication/addition is thus elementwise/per-site.\n",
    "\n",
    "The _parameters defining the transform_, $s(\\phi_2)$ and $t(\\phi_2)$, can be complicated, non-invertible functions of the frozen variables $\\phi_2$; **we'll use neural nets for these.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cf0f18",
   "metadata": {
    "id": "e2cf0f18"
   },
   "source": [
    "The partioning of variables ensures that the Jacobian is triangular,\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial g(\\phi_1, \\phi_2)}{\\partial (\\phi_1, \\phi_2)} =\n",
    "\\left( \\begin{matrix}\n",
    "    \\frac{\\partial \\phi_1'}{\\partial \\phi_1} & \\frac{\\partial \\phi_1'}{\\partial \\phi_2} \\\\\n",
    "    0 & 1\n",
    "\\end{matrix} \\right).\n",
    "\\end{equation}\n",
    "\n",
    "which makes for a simpler determinant that doesn't involve many combinations. \n",
    "\n",
    "For a transform that is just a shift, scale or stratech (aka [affine transformation](https://en.wikipedia.org/wiki/Affine_transformation)), this takes the form\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial g(\\phi_1, \\phi_2)}{\\partial (\\phi_1, \\phi_2)} =\n",
    "\\left( \\begin{array}{ccc|ccc}\n",
    "    e^{[s(\\phi_2)]_1} & & & \\cdot & \\cdot & \\cdot \\\\\n",
    "    & e^{[s(\\phi_2)]_2} & & \\cdot & \\cdot & \\cdot \\\\\n",
    "    & & \\ddots & \\cdot & \\cdot & \\cdot \\\\\n",
    "    \\hline\n",
    "    & & & 1 & & \\\\\n",
    "    & 0 & & & 1 & \\\\\n",
    "    & & & & & \\ddots\n",
    "\\end{array} \\right)\n",
    "\\end{equation}\n",
    "\n",
    "so that the Jacobian determinant factor is just right down the diagonals\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\phi) = \\left|\\det_{kl} \\frac{\\partial [g(\\phi_1, \\phi_2)]_k}{\\partial (\\phi_1, \\phi_2)} \\right| = \\prod_{k} e^{[s(\\phi_2)]_k}\n",
    "\\end{equation}\n",
    "\n",
    "which is tractably computable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0177d71",
   "metadata": {
    "id": "b0177d71"
   },
   "source": [
    "In this example, we define the active ($\\phi_1$) and frozen ($\\phi_2$) subsets by assigning $\\phi_{i}$ to specific elements in a 2D square array and constructing checkerboard masks that assign one square to be either active or frozen. This approach is akin to the leap-frog symplectic integrators, but now in 2D. \n",
    "\n",
    "As a result, this allows sites to influence the transformation of their direct neighbors and build local correlations. To ensure all variables are updated, we compose coupling layers that alternatingly update odd sites and even sites, effectively a 2D leap-frog, just with a checkboards alternating active and frozen. \n",
    "\n",
    "\n",
    "[**Aside:** In all the code below, for the mask $m(\\vec{n}) \\in \\{0, 1\\}$, if $m(\\vec{n}) = 1$ then $\\phi(\\vec{n})$ is frozen and vice versa. This is just a convention.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3330f16b",
   "metadata": {
    "id": "3330f16b"
   },
   "outputs": [],
   "source": [
    "def make_checker_mask(shape, parity):\n",
    "    checker = torch.ones(shape, dtype=torch.uint8) - parity\n",
    "    checker[::2, ::2] = parity\n",
    "    checker[1::2, 1::2] = parity\n",
    "    return checker.to(torch_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc30a8d1",
   "metadata": {
    "id": "bc30a8d1"
   },
   "source": [
    "The code below defines an affine coupling layer. Using the formualae above for the inverse and the example of forward for the base affine transform, compute the reverse transform. \n",
    "\n",
    "[**Aside:** class field `net` is an instance of the CNN like the ones defined above. It has one input channel (the frozen sites of the scalar field, with zeros for the active sites), and two output channels (one for $s$, one for $t$). The net produces outputs $s$ and $t$ with nonzero elements for the frozen sites, which are simply ignored using masks.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98aa088",
   "metadata": {
    "id": "d98aa088",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class AffineCoupling(torch.nn.Module):\n",
    "    def __init__(self, net, *, mask_shape, mask_parity):\n",
    "        super().__init__()\n",
    "        self.mask = make_checker_mask(mask_shape, mask_parity)\n",
    "        self.net = net\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_frozen = self.mask * x      \n",
    "        x_active = (1 - self.mask) * x\n",
    "        net_out = self.net(x_frozen.unsqueeze(1))\n",
    "        s, t = net_out[:,0], net_out[:,1]\n",
    "        fx = (1 - self.mask) * t + x_active * torch.exp(s) + x_frozen\n",
    "        axes = range(1,len(s.size()))\n",
    "        logJ = torch.sum((1 - self.mask) * s, dim=tuple(axes))\n",
    "        return fx, logJ\n",
    "\n",
    "    def reverse(self, fx):\n",
    "        # You will need to impelemnt this method as an exercise\n",
    "        #setup masks\n",
    "        #compute s,t of phi' frozen usin network\n",
    "        #now compute formula above note s is s(phi') and t is t(phi')\n",
    "        x =  #add code here\n",
    "        logJ = #add code here\n",
    "        #return x, logJ\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a91c75",
   "metadata": {
    "id": "14a91c75"
   },
   "source": [
    "#### **Exercise: Invertability test**\n",
    "\n",
    "Normalizing flows are defined using a flow transformation that must be a diffeomorphism, which means that it must be both invertible and differentiable. If this condition is not met, it can result in an ill-defined posterior density and break ergodicity. Hence, using such a flow to generate samples for computations of physical observables can lead to uncontrollable bias. Although we know from mathematics that the affine flow transformation must be invertible, it is still useful to verify this numerically, as errors in our code can occur.\n",
    "\n",
    "To ensure that flow transformation is diffeorophism we need to check that 1) flow transformation is invertable and 2) invertability of jacobian of forward and inverse transfromation. To do so we need:\n",
    "\n",
    "1) generate random fields\n",
    "$$z_0 â† \\text{random()}$$\n",
    "2) apply flow transformation, and compute jacobian\n",
    "$$x = f(z_0), \\quad \\text{logJ}=\\log |\\det \\frac{\\partial z_0}{\\partial x}|$$\n",
    "3) apply reverse tranfromation\n",
    "$$z_1 = f^{-1}(x), \\quad \\text{logJ1}= \\text{logJ}= \\log |\\det \\frac{\\partial x}{\\partial z_1}|$$\n",
    "4) and verify that \n",
    "$$z_1 == z_0, \\quad \\text{logJ} == -\\text{logJ1} $$\n",
    "\n",
    "In the previous cell, we introduced a coupling class for affine transformation. The `forward()` method of this class computes and returns the tuple `(f(z), logJ`). To ensure that the transformation is a diffeomorphism, you need to define the `reverse()` method for this class which should return `(f^{-1}(x), logJ1)`, and verify the diffeomorphism properties as outlined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f100195",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "0f100195",
    "outputId": "a4838331-8a06-4e3a-c8a4-9a6bb680ce1b"
   },
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "L = 4\n",
    "\n",
    "# makes the coupling layer\n",
    "net = make_conv_net(in_channels=1, out_channels=2, hidden_sizes=[16], kernel_size=3)\n",
    "layer = AffineCoupling(net=net, mask_shape=(L,L), mask_parity=1).to(torch_device)\n",
    "\n",
    "# makes a toy field of the appropriate size/shape\n",
    "z0 = torch.arange(L**2).reshape(1,L,L).type(torch.FloatTensor).to(torch_device)\n",
    "\n",
    "x, logJ0 = # INSERT CODE HERE\n",
    "z1, logJ1 = # INSERT CODE HERE\n",
    "\n",
    "# TODO: compare using torch.allclose\n",
    "assert torch.allclose(z0, z1)\n",
    "assert torch.allclose(logJ0, -logJ1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xxg-p3toWMeN",
   "metadata": {
    "id": "xxg-p3toWMeN"
   },
   "source": [
    "#### **Exercise: logJ test**\n",
    "\n",
    "Having the correct value for `logJ` is crucial in practice, as incorrect values can result in wrong gradients that prevent successful training of the model. Therefore, it is a good practice to verify the `logJ` value that is implemented in the coupling class.\n",
    "\n",
    "In this exercise, you will need to implement a function to verify the `logJ` value and perform tests for the affine coupling class that was defined earlier. You can use the following hints to guide your implementation:\n",
    "\n",
    "1) To simplify the computations, it is recommended to perform them for a batch size of one.\n",
    "\n",
    "2) The `torch.autograd.grad(y_j, x)` function can be used to compute the gradients $\\frac{\\partial y_j}{\\partial x_i}$.\n",
    "\n",
    "3) To compute the whole Jacobian matrix `J`, you can repeat the computations for its columns `y_j`.\n",
    "\n",
    "4) The `linalg.slogdet(J)` function can be used to obtain the required logJ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DUbGnaKwNYNz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DUbGnaKwNYNz",
    "outputId": "e140133f-c95d-4f48-b25a-e18ab3aa7240"
   },
   "outputs": [],
   "source": [
    "def check_logJ(z, coupling):\n",
    "    z.requires_grad = True #add this so you can use torch.autograd.grad(fx[i],z) later to get derivative\n",
    "    #compute logJ and fx\n",
    "    \n",
    "    #Loop over fx elements and run torch.autograd.grad(fx[i],z) and add to torch J\n",
    "\n",
    "    #Finally once you have computed J get log determinant like below\n",
    "    logJ1 = np.linalg.slogdet(J)[1]\n",
    "    \n",
    "    #Check it works\n",
    "    assert np.allclose(logJ, logJ1, atol=1e-5), \\\n",
    "        f'|logJ_model - logJ_torch| = {logJ - logJ1}'\n",
    "\n",
    "check_logJ(z0, layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a84a6ea",
   "metadata": {
    "id": "5a84a6ea"
   },
   "source": [
    "### **Composition**\n",
    "\n",
    "The helper function below just builds a sequence of coupling layers with alternating-parity checkerboards, providing a separate neural net for each with the same hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980d7fd8",
   "metadata": {
    "id": "980d7fd8"
   },
   "outputs": [],
   "source": [
    "def make_phi4_layers(*, n_layers, lattice_shape, hidden_sizes, kernel_size):\n",
    "    layers = []\n",
    "    for i in range(n_layers):\n",
    "        parity = i % 2\n",
    "        net = make_conv_net(\n",
    "            in_channels=1, out_channels=2, hidden_sizes=hidden_sizes,\n",
    "            kernel_size=kernel_size)\n",
    "        coupling = AffineCoupling(net, mask_shape=lattice_shape, mask_parity=parity)\n",
    "        layers.append(coupling)\n",
    "    return torch.nn.ModuleList(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c481729",
   "metadata": {
    "id": "0c481729"
   },
   "source": [
    "Since we will a apply many functions $f_{1}(f_{2}(x))\\rightarrow f_{i}(...)$. The Jacobian factors $J_i$ from each coupling layer simply multiply together following the chain rule to define the Jacobian factor of the composed function, so that the final density is\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    q(x) &= r(z) \\left| \\det \\frac{\\partial f(z)}{\\partial z} \\right|^{-1} = r(z) \\prod_{i} J_i^{-1}.\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "In practice, we'll add together log Jacobians instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662cabc5",
   "metadata": {
    "id": "662cabc5"
   },
   "outputs": [],
   "source": [
    "def apply_flow_to_prior(prior, coupling_layers, *, batch_size):\n",
    "    x = prior.sample_n(batch_size)\n",
    "    logq = prior.log_prob(x)\n",
    "    for layer in coupling_layers:\n",
    "        x, logJ = layer.forward(x)\n",
    "        logq = logq - logJ\n",
    "    return x, logq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d524c8",
   "metadata": {
    "id": "14d524c8"
   },
   "source": [
    "### Model\n",
    "\n",
    "We now have everything we need to make a flow model. The cell below instantiates one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb01431",
   "metadata": {
    "id": "fdb01431"
   },
   "outputs": [],
   "source": [
    "L = 16\n",
    "lattice_shape = (L,L)\n",
    "prior = SimpleNormal(torch.zeros(lattice_shape), torch.ones(lattice_shape))\n",
    "\n",
    "n_layers = 16\n",
    "hidden_sizes = [8,8]\n",
    "kernel_size = 3\n",
    "layers = make_phi4_layers(\n",
    "    lattice_shape=lattice_shape, n_layers=n_layers, \n",
    "    hidden_sizes=hidden_sizes, kernel_size=kernel_size)\n",
    "\n",
    "model = {'layers': layers, 'prior': prior}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e0ddce",
   "metadata": {
    "id": "44e0ddce"
   },
   "source": [
    "Draw 16 configurations from the untrained flow model. What do they look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a44e37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "16a44e37",
    "outputId": "b8624187-430f-4986-966e-11f118475942"
   },
   "outputs": [],
   "source": [
    "x, logq = apply_flow_to_prior(model['prior'], model['layers'], batch_size=16)\n",
    "\n",
    "fig,axes = plt.subplots(4,4, figsize=(5,5), sharex=True, sharey=True)\n",
    "for ax, x0 in zip(axes.ravel(),x):\n",
    "    ax.imshow(grab(x0).squeeze().T, aspect='equal')\n",
    "    ax.grid(False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87528bc4",
   "metadata": {
    "id": "87528bc4"
   },
   "source": [
    "Now an important question to consider is what is the appropriate function $f$ in the normalizing flow that we sample that gets us to the right answer. \n",
    "\n",
    "Determining whether a model is a good fit for the target action is a challenging question to answer in general. However, one metric that can be used to assess model performance is the effective sample size (ESS) per configuration. In the following, we will be writing ESS but have in mind ESS per configuration.\n",
    "\n",
    "ESS is defined on the interval $[0,1]$, and can be thought of as an effective percentage of configurations from the dataset generated from the target(fully correct) distribution that would yield the same statistics. This essentially like the efficiency of accepts when running a Markov chain sampler. For example, if a model generates 100 configurations with an ESS of 0.7, computing observables on these data would yield the same uncertainties as if you computed observables only on 70 configurations generated from the target distribution.\n",
    "\n",
    "For MCMC, if we consider randomly sampled variables $X_{i}=\\frac{p_{i}}{q_{i}}$ ie the random variable we sample to make the Markov Chain decision, we can write \n",
    "\n",
    "$$\n",
    "\\rm{ESS} = \\frac{N}{1+2\\sum_{i}{\\rm Corr}(X_{i},X_{j})}\n",
    "$$\n",
    "Or in other words, if we have the correct distribution $p$ the our randomly sampled $x_{i}$ have no correlation. If they are correlated, we have a biased sampler. A little bit of math, will allow us to rewrite it in a convenient way for this problem. Here, If we have the predicted distribution $q$ and the true distribution $p$ we can write this as. \n",
    "\n",
    "$$\n",
    "\\frac{1}{\\rm{ESS}} = \\frac{\\left(\\sum_{i} \\frac{p_{i}}{q_{i}}\\right)^{2}}{N\\sum_{i}\\left( \\frac{p_{i}}{q_{i}}\\right)^{2}}\\\\\n",
    "\\frac{1}{\\rm{ESS}} = \\frac{1}{N}\\exp\\left(\\log\\left(\\left(\\sum_{i} \\frac{p_{i}}{q_{i}}\\right)^{2}\\right) - \\log\\left(\\sum_{i}\\left( \\frac{p_{i}}{q_{i}}\\right)^{2}\\right)\\right)\\\\\n",
    "$$\n",
    "\n",
    "Which is what we compute below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc2bdfb",
   "metadata": {
    "id": "1bc2bdfb"
   },
   "outputs": [],
   "source": [
    "def compute_ess(logp, logq):\n",
    "    logw = logp - logq\n",
    "    log_ess = 2*torch.logsumexp(logw, dim=0) - torch.logsumexp(2*logw, dim=0)\n",
    "    ess_per_cfg = torch.exp(log_ess) / len(logw)\n",
    "    return ess_per_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf864970",
   "metadata": {
    "id": "cf864970"
   },
   "source": [
    "### **Train the model**\n",
    "\n",
    "For convenience, the cell below instantiates the model and everything we need to train it. We'll work with very small lattices with $L=4$ so training goes quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97b9508",
   "metadata": {
    "id": "f97b9508"
   },
   "outputs": [],
   "source": [
    "# Lattice Theory\n",
    "torch_device = 'cpu'#'cuda'\n",
    "Lx, Lt = 16, 8\n",
    "lattice_shape = (Lx,Lt)\n",
    "M2 = -4.0\n",
    "lam = 8.0\n",
    "\n",
    "#kappa? \n",
    "#lam reparametrization here? \n",
    "phi4_action = ScalarPhi4Action(M2=M2, lam=lam)\n",
    "\n",
    "# Model\n",
    "prior = SimpleNormal(torch.zeros(lattice_shape, device=torch_device), torch.ones(lattice_shape, device=torch_device))\n",
    "\n",
    "n_layers = 16\n",
    "hidden_sizes = [8,8]\n",
    "kernel_size = 3\n",
    "layers = make_phi4_layers(\n",
    "    lattice_shape=lattice_shape,\n",
    "    n_layers=n_layers, \n",
    "    hidden_sizes=hidden_sizes,\n",
    "    kernel_size=kernel_size\n",
    "    ).to(torch_device)\n",
    "model = {'layers': layers, 'prior': prior}\n",
    "\n",
    "# Training\n",
    "base_lr = 0.001\n",
    "optimizer = torch.optim.Adam(model['layers'].parameters(), lr=base_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd92b11",
   "metadata": {
    "id": "5dd92b11"
   },
   "source": [
    "We need to optimize the coupling layers to match the model distribution $q(\\phi)$ to the target one $p(\\phi)$. To do this, we minimize a quantity known as the Kullback-Leibler (KL) divergence, which measures the distance between two distributions. Training data drawn from $p$ can be scarce in simulations of lattice field theories, so we make use of the \"reverse\" KL divergence,\n",
    "estimated using $N$ samples drawn from the model distribution ($\\phi_i \\sim q$) as\n",
    "\\begin{equation}\n",
    "\\widehat{D}_{KL}(q || p) = \\frac{1}{N} \\sum_{i=1}^N \\left[ \\log{q}(\\phi_i) - \\log{p}(\\phi_i) \\right] \\quad \\left( \\phi_i \\sim q \\right).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efea31e",
   "metadata": {
    "id": "6efea31e"
   },
   "source": [
    "We use a \"reverse KL self-training\" protocol that consists of\n",
    "  1. Drawing samples $\\phi_i$ and density estimates $\\log q(\\phi_i)$ from the model\n",
    "  2. Computing $\\log p(\\phi_i) \\propto -S(\\phi_i)$ on each sample\n",
    "  3. Using $\\log q$ and $\\log p$ to compute the reverse KL divergence over the samples\n",
    "  3. Using standard stochastic gradient descent methods (i.e. Adam) to iteratively update neural network weights\n",
    "  \n",
    "  \n",
    "#### **Exercise: Training Normalizing flow model**\n",
    "In this exercise, you will need to implement a training function by following the algorithm outlined above. During training, we collect statistics to monitor how the training is progressing. Our built-in function will use these statistics to plot a training figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c84df7",
   "metadata": {
    "id": "90c84df7"
   },
   "outputs": [],
   "source": [
    "def train_step(model, action, optimizer, metrics):\n",
    "    layers, prior = model['layers'], model['prior']\n",
    "\n",
    "    # code training\n",
    "    \n",
    "    # you will also need to add these metrics\n",
    "    metrics['loss'].append(...)\n",
    "    metrics['logp'].append(...)\n",
    "    metrics['logq'].append(...)\n",
    "    metrics['ess'].append(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2612e785",
   "metadata": {
    "id": "2612e785"
   },
   "source": [
    "Finally, let's choose hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37976456",
   "metadata": {
    "id": "37976456"
   },
   "outputs": [],
   "source": [
    "N_era = 1\n",
    "N_epoch = 200\n",
    "batch_size = 1024 * 8\n",
    "print_freq = 10\n",
    "plot_freq = 1\n",
    "\n",
    "history = {\n",
    "    'loss' : [],\n",
    "    'logp' : [],\n",
    "    'logq' : [],\n",
    "    'ess' : [],\n",
    "    'dkl' : []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4627a06b",
   "metadata": {
    "id": "4627a06b"
   },
   "source": [
    "and run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d07ab8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "59d07ab8",
    "outputId": "4c3c317b-f6b9-4e1c-945e-93c543d6944d"
   },
   "outputs": [],
   "source": [
    "\n",
    "[plt.close(plt.figure(fignum)) for fignum in plt.get_fignums()] # close all existing figures\n",
    "live_plot = init_live_plot()\n",
    "\n",
    "for era in range(N_era):\n",
    "    for epoch in range(N_epoch):\n",
    "        train_step(model, phi4_action, optimizer, history)\n",
    "\n",
    "        if epoch % print_freq == 0:\n",
    "            print_metrics(history, avg_last_N_epochs=print_freq)\n",
    "\n",
    "        if epoch % plot_freq == 0:\n",
    "            update_plots(history, **live_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5a2112",
   "metadata": {
    "id": "5c5a2112"
   },
   "source": [
    "The cell below draws a batch of configurations from the sample, computes $S(\\phi)$ and $S_{\\text{eff}} \\equiv - \\log q(\\phi)$ on each one, then makes a 2d histogram comparing these quantities.\n",
    "\n",
    "**Discuss:** What would this look like for a perfect model? How does your model compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b529ecb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "2b529ecb",
    "outputId": "7535a1bd-5d78-4243-cdd7-c97b31503f18"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  phi, logq = apply_flow_to_prior(model['prior'], model['layers'], batch_size=1024)\n",
    "S_eff = -grab(logq)\n",
    "S = grab(phi4_action(phi))\n",
    "fit_b = np.mean(S) - np.mean(S_eff)\n",
    "print(f'slope 1 linear regression S = S_eff + {fit_b:.4f}')\n",
    "fig, ax = plt.subplots(1,1, dpi=125, figsize=(4,4))\n",
    "ax.hist2d(S_eff, S, bins=40, range=[[-5, 10], [-5, 10]])\n",
    "ax.set_xlabel(r'$S_{\\mathrm{eff}} = -\\log~q(x)$')\n",
    "ax.set_ylabel(r'$S(x)$')\n",
    "ax.set_aspect('equal')\n",
    "xs = np.linspace(-5, 10, num=4, endpoint=True)\n",
    "ax.plot(xs, xs + fit_b, ':', color='w', label='slope 1 fit')\n",
    "plt.legend(prop={'size': 6})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "go7pYuwD46Ex",
   "metadata": {
    "id": "go7pYuwD46Ex"
   },
   "source": [
    "## Metropolis-Hastings algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cbea1f",
   "metadata": {
    "id": "63cbea1f"
   },
   "source": [
    "The Metropolis-Hastings algorithm is a Markov chain Monte Carlo (MCMC) method that generates samples for probability distributions when direct sampling is difficult or impossible. The algorithm constructs a sequence of configurations starting from an arbitrary configuration, with the sequence eventually following the target distribution. The algorithm can be summarized as follows:\n",
    "\n",
    "1) Generate a new candidate configuration $\\phi'$ from the previous configuration $\\phi^{i-1}$ with a proposal probability $T(\\phi^{i-1}\\rightarrow \\phi')$.\n",
    "\n",
    "2) Accept the candidate configuration $\\phi'$ as the new configuration $\\phi^i$ with an acceptance probability:\n",
    "\\begin{equation}\n",
    "p_{\\mathrm{accept}}(\\phi'|\\phi^{i-1}) = \\min \\left(\n",
    "1,\n",
    "\\frac{T(\\phi' \\rightarrow \\phi^{i-1})}{T(\\phi^{i-1} \\rightarrow \\phi')}\n",
    "\\frac{p(\\phi')}{p(\\phi^{i-1})}\n",
    "\\right),\n",
    "\\end{equation}\n",
    "where $p(\\phi)$ is the target probability density. If the suggested configuration is not accepted, the unchanged configuration is considered again in the sequence as $\\phi^i = \\phi^{i-1}$.\n",
    "\n",
    "3) Repeat the steps to generate full ensemble.\n",
    "\n",
    "It can be shown that samples generated with this algorithm are distributed according to the targeted probability density if $T(\\phi^{i-1} \\rightarrow \\phi')$ is ergodic, meaning that there is a non-zero probability to generate all possible configurations $\\phi'$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0NVNXPLt8I8Z",
   "metadata": {
    "id": "0NVNXPLt8I8Z"
   },
   "source": [
    "### Metropolis algorithm for normalizing flow\n",
    "To obtain **unbiased** estimates of observables, we can use the samples generated by our model as proposals in the Metropolis-Hastings (MH) algorithm. Using normalizing flows, we can assign a probability density $q(\\phi)$ to each sample $\\phi$, and this density can be used as the proposal probability in the MH algorithm. In this case, the acceptance probability takes the form:\n",
    "\n",
    "\\begin{equation}\n",
    "p_{\\mathrm{accept}}(\\phi'|\\phi^{i-1}) = \\min \\left(\n",
    "1,\n",
    "\\frac{q(\\phi^{i-1})}{q(\\phi')}\n",
    "\\frac{p(\\phi')}{p(\\phi^{i-1})}\n",
    "\\right).\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_5T630PDEz8n",
   "metadata": {
    "id": "_5T630PDEz8n"
   },
   "source": [
    "To simplify the process, we create a function that generates and draws batches of samples from a flow model and then returns them one at a time, along with their respective $\\log p$ and $\\log q$ values. We can use each sample as a proposal in the MH algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c486dbe",
   "metadata": {
    "id": "4c486dbe"
   },
   "outputs": [],
   "source": [
    "def serial_sample_generator(model, action, batch_size, N_samples):\n",
    "    layers, prior = model['layers'], model['prior']\n",
    "    layers.eval()\n",
    "    x, logq, logp = None, None, None\n",
    "    with torch.no_grad():\n",
    "      for i in range(N_samples):\n",
    "          batch_i = i % batch_size\n",
    "          if batch_i == 0:\n",
    "              # we're out of samples to propose, generate a new batch\n",
    "              x, logq = apply_flow_to_prior(prior, layers, batch_size=batch_size)\n",
    "              logp = -action(x)\n",
    "          yield x[batch_i], logq[batch_i], logp[batch_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PaDUpqN4FJ_V",
   "metadata": {
    "id": "PaDUpqN4FJ_V"
   },
   "source": [
    "If you are not familiar with Python generators, this function creates an object that you can iterate over, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WFliN0UuFYiG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WFliN0UuFYiG",
    "outputId": "905c9d67-f516-4839-f8f2-316fd06e181c"
   },
   "outputs": [],
   "source": [
    "l = [phi.mean() for phi, _, _ in serial_sample_generator(model, phi4_action, 4, 6)]#vary the 6=> something what happens\n",
    "print(\"Field values:\", l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83efa8f",
   "metadata": {
    "id": "c83efa8f"
   },
   "source": [
    "#### **Exercise: Metroplis-Hastings for NF samples** \n",
    "Now we want you to setup the full Markov Chain MC sampling using everything you trained above! You are going to have to go up and follow things carefully, but its all here. An important point to consider is the serial step should be viewed as sequential Markov Chain Proposals. \n",
    "\n",
    "In this exercise, aka the function below, your goal is to create an MCMC ensemble using independent flow proposals and the acceptance probability formula we defined above. It's recommended to keep track of the history of some metrics, compute them, and add them to a dictionary. We will output the history later and use it to study the dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c1961f",
   "metadata": {
    "id": "d8c1961f"
   },
   "outputs": [],
   "source": [
    "def make_mcmc_ensemble(model, action, batch_size, N_samples):\n",
    "    # fill this history dict with values in MCMC ensemble\n",
    "    history = {\n",
    "        'x' : [],  # save configurations here\n",
    "        'logq' : [],\n",
    "        'logp' : [],\n",
    "        'accepted' : []\n",
    "    }\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22f2003",
   "metadata": {
    "id": "a22f2003"
   },
   "source": [
    "The Independence Metropolis acceptance rate is another metric to evaluate the quality of our model, similar to the ESS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96f15c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d96f15c9",
    "outputId": "8a081162-e08a-4a05-fa57-748ae4f7297c"
   },
   "outputs": [],
   "source": [
    "ensemble_size = 32*1024\n",
    "phi4_ens = make_mcmc_ensemble(model, phi4_action, 1024, ensemble_size)\n",
    "print(\"Accept rate:\", np.mean(phi4_ens['accepted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdce9a6",
   "metadata": {
    "id": "7fdce9a6"
   },
   "source": [
    "The NF model generates samples with a probability density `q(x)` that only approximates the target density `p(x)` to some degree. By applying the MH algorithm, we obtain samples that are distributed exactly according to the target density. The quality of the model's approximation can be evaluated using metrics such as ESS or acceptance rate, which we previously calculated.\n",
    "\n",
    "Next, let's visualize the bias in \"raw\" sample or approximation error by plotting the distribution of the action of the theory. Note that bias in different observables could be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae3b199",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "aae3b199",
    "outputId": "bfa87c21-9974-4d25-9bf3-49e144706b02"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  phi, _ = apply_flow_to_prior(model['prior'], model['layers'], batch_size=ensemble_size)\n",
    "phi_unbiased = torch.stack(phi4_ens['x'])\n",
    "\n",
    "S, S_unbiased = map(lambda x: phi4_action(x).cpu(), [phi, phi_unbiased])\n",
    "plt.hist(torch.stack([S, S_unbiased]), label=['model action', 'MCMC corrected action'], bins=100, density=1, histtype='step');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NtMiwvM6fZnv",
   "metadata": {
    "id": "NtMiwvM6fZnv"
   },
   "source": [
    "### **Exercise (optional): training better model and examining approximation error**\n",
    "\n",
    "The results obtained may vary depending on the quality of the model used. We encourage you to experiment with various hyperparameters, such as the CNN configuration, Adam parameters, and increasing the training duration to obtain better results. It is interesting to observe how the model samples approach the true samples as the model quality improves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gG4CGQ2eI-1-",
   "metadata": {
    "id": "gG4CGQ2eI-1-"
   },
   "source": [
    "## Thermodynamics with Normalizing Flows (Not Optional...well) \n",
    "### Really, this is  The Ising on the cake! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K5uSxFwtJ9dv",
   "metadata": {
    "id": "K5uSxFwtJ9dv"
   },
   "source": [
    "The thermodynamics of QCD has important implications for high-energy heavy-ion collision experiments, such as those performed at the Relativistic Heavy Ion Collider (RHIC) and the Large Hadron Collider (LHC). These experiments aim to recreate the conditions present in the early universe just after the Big Bang, and the study of QCD thermodynamics is essential for understanding the behavior of matter under these extreme conditions.\n",
    "\n",
    "The thermodynamic properties of a system can be determined from the partition function\n",
    "$$\n",
    "Z(T,V) = \\int \\prod_{\\vec{n}} d\\phi(\\vec{n}) ~ e^{-\\frac{S(\\phi)}{T}},\n",
    "$$\n",
    "where $V$ denotes the physical volume of the system and $T$ is temperature. In lattice QCD, one uses the MCMC method to generate configurations ${\\phi}$ with probabilities proportional to $e^{-\\frac{S(\\phi)}{T}}$ and evaluate observables on these configurations. However, this method does not provide direct access to the normalizer of the probability density, $Z(T,V)$, making a study of thermodynamics a challenging problem.\n",
    "\n",
    "Computation of patition function $Z(T,V)$ involves some approximations and tricks. Typically, these tricks rely on the fact that the ratio of partition functions  $Z(T,V)/Z(T_0,V)$ at different physical parameters $T$ and $T_0$ can be computed using samples without requiring constant normalizers. This ratio is then used to compute the partition function at the desired parameters. For instance, a possible approach would be to start from a known analytical value $Z (T_ 0, V)$. Next, one would execute MCMC simulations to compute $\\frac{ Z(T,V)}{Z(T_ 0,V)}$. By combining these two results, one can obtain an interesting quantity $Z(T,V)=\\frac{ Z(T,V)}{Z(T_ 0,V)} Z (T_ 0, C)$.\n",
    "\n",
    "In practical simulations, the computation of the ratio of partition functions can be challenging due to the requirement of a good overlap of the probability densities corresponding to both partition functions in the ratio. The degree of overlap significantly decreases with changes in physical parameters, which means that the ratio can only be computed for closely related values. As a result, the interval of interest, say $[T, T_0]$, is split into a few small intervals where the overlap is good enough, and MCMC simulations are carried out for every value. This approach is computationally demanding, making the study of QCD thermodynamics a challenging problem.\n",
    "\n",
    "Normalizing Flows provide an alternative approach. Comparing with conventional MCMC they not only generate samples $\\phi$, but also provide the corresponding probability density. One can compute the partition function using the probability density provided by Normalizing Flows in a way similar to computing other observables.  This advantage allows the generation of **only one ensemble** of configurations and directly evaluates the partition function on it.  The new approach reduces the computational demand significantly and allows one to perform computations when the partition function is unknown for some base parameters.\n",
    "\n",
    "\n",
    "In practical simulations, it is more common to calculate the Free Energy, which can be expressed as:\n",
    "$$\n",
    "F = - T \\, \\log Z,\n",
    "$$\n",
    "with $T$ being the absolute temperature. In lattice QCD with periodic boundary conditions tempreture can be expresses as $T = \\frac{1}{L_t \\, a}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GpyIbYd9Pi26",
   "metadata": {
    "id": "GpyIbYd9Pi26"
   },
   "source": [
    "### **Exercise**: Estimator of logZ\n",
    "\n",
    "In this exercise, you will need to write an estimator for Partition function $Z$ using samples generated with probability density $q(\\phi)$.\n",
    "\n",
    "**Hint:** Start with definition of Parition function $Z$ and reweight integrand with density $q(\\phi)$. After that you can use MC formula (aka average over all of $\\phi$) to estimate the integral.\n",
    "\n",
    "or more explicitly Recall : \n",
    "\n",
    "\\begin{equation}\n",
    "p(\\phi) = \\frac{1}{Z} e^{-S(\\phi)}, \\quad\n",
    "Z \\equiv \\int \\prod_{\\vec{n}} d\\phi(\\vec{n}) ~ e^{-S(\\phi)},\n",
    "\\end{equation}\n",
    "\n",
    "and that $q(\\phi)$ approximates $p$, then by averaging over all $\\phi_{i}$ we get an esimate for $Z$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WuelFlabNLvj",
   "metadata": {
    "id": "WuelFlabNLvj"
   },
   "source": [
    "### Exercise - mini-project: Free energy computation with NF\n",
    "\n",
    "For this mini-project, your task is to train a Normalizing Flow model and compute the free energy of scalar field theory for a specific set of physical parameters (mass and coupling). You will be able to compare your results with the values obtained in arXiv:2007.07115, which will enable you to verify your work. This project closely resembles a real scientific problem, essentially, you would just need to apply all skill you learned to action of interest. \n",
    "\n",
    "You will need:\n",
    "\n",
    "1) Map action used in arXiv:2007.07115 to the action we used in this tutorial. Hopefully, you have already accomplished it in one of the previous exercises. We propose you to use physical parameters $\\kappa=0.3$, $\\lambda=0.022$ and lattice $L_t = 8$, $L_x=16$ as the smallest lattice from arXiv:2007.07115. **Hint:** when rescale ation do not forget to resacat $Z$ in a final formula.\n",
    "\n",
    "2) Define a more expressive NF model and train it. It may require training it longer or even changing optimizer and/or optimizer hyperparameters.\n",
    "\n",
    "3) Generate an ensemble of configurations using the MH algorithm as we did in previous sections.\n",
    "\n",
    "4) Compute $Z$ using an estimator defined in a previous exercise. Compute free energy normalized by volume\n",
    "$$\n",
    "\\frac{F}{V} a^2= \\frac{1}{L_tL_x} \\log \\, Z\n",
    "$$\n",
    "\n",
    "**Hint:** Use `logsumexp` for numerical stability.\n",
    "\n",
    "5) Estimate errors (This is Optional). Provide answers for free energy with uncertainties and compare your results with arXiv:2007.07115 Fig.2. **Hint:** Ensembles generated with MCMC often have large autocorrelations, which can result in underestimated uncertainties. Therefore, to estimate errors reliably, you can use various algorithms like  [binning](https://en.wikipedia.org/wiki/Data_binning#:~:text=Statistical%20data%20binning%20is%20a,grouping%20every%20five%20years%20together). For computing the uncertainty of a function of a random quantity, we suggest using the [bootstrap algorith](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html), or in otherword just taking mean and standard deviation by repeating the calculation removing some elements.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YiphsmfYb1Y2",
   "metadata": {
    "id": "YiphsmfYb1Y2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "901a0423"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
